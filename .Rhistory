?SAheart
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = 'glm', family = 'binomial')
?train
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
head(trainSA)
head(predict(modFit, trainSA))
missClass(trainSA$chd, predict(modFit, trainSA))
missClass(testSA$chd, predict(modFit, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
vowel.test
?as.factor
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
?train
set.seed(33833)
modFit <- train(y ~ ., data = vowel.train, method = 'rf')
modFit <- train(y ~ ., data = vowel.train, method = 'rf')
set.seed(33833)
modFit <- train(y ~ ., data = vowel.train, method = 'rf')
varImp(modFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
modFit <- train(y ~ ., data = vowel.train, method = 'rf')
?varImp
varImp(modFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
modFit <- train(y ~ ., data = vowel.train, method = 'rf')
varImp(modFit)
q()
fit.gbm <- train(y ~ ., data = train, method = 'gbm')
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
train <- vowel.train
test <- vowel.test
train$y <- as.factor(train$y)
test$y <- as.factor(test$y)
set.seed(33833)
fit.rf <- train(y ~ ., data = train, method = 'rf')
fit.gbm <- train(y ~ ., data = train, method = 'gbm')
pred.rd <- predict(fit.rf, test)
pred.rf <- predict(fit.rf, test)
pred.gbm <- predict(fit.gbm, test)
pred.rf
pred.rf == test$y
sum(pred.rf == test$y)
281/528
sum(pred.gbm == test$y) / 528
TRUE
sum(TRUE)
pred.rf == pred.gbm
pred.rf[pred.rf == pred.gbm]
pred.rf[pred.rf == pred.gbm] == test$y[pred.rf == pred.gbm]
length(pred.rf[pred.rf == pred.gbm] == test$y[pred.rf == pred.gbm])
sum(pred.rf[pred.rf == pred.gbm] == test$y[pred.rf == pred.gbm]) / length(pred.rf[pred.rf == pred.gbm] == test$y[pred.rf == pred.gbm])
?ratio
ratio <- function (x) {sum(x)/length(x)}
ratio(c(1,2))
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
train <- vowel.train
test <- vowel.test
train$y <- as.factor(train$y)
test$y <- as.factor(test$y)
set.seed(33833)
fit.rf <- train(y ~ ., data = train, method = 'rf')
fit.gbm <- train(y ~ ., data = train, method = 'gbm')
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
train <- vowel.train
test <- vowel.test
train$y <- as.factor(train$y)
test$y <- as.factor(test$y)
set.seed(33833)
fit.rf <- train(y ~ ., data = train, method = 'rf')
fit.gbm <- train(y ~ ., data = train, method = 'gbm')
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
train <- vowel.train
test <- vowel.test
train$y <- as.factor(train$y)
test$y <- as.factor(test$y)
set.seed(33833)
fit.rf <- train(y ~ ., data = train, method = 'rf')
fit.gbm <- train(y ~ ., data = train, method = 'gbm', verbose = F)
pred.rf <- predict(fit.rf, test)
pred.gbm <- predict(fit.gbm, test)
ratio <- function (x) {sum(x)/length(x)}
ratio(pred.rf == test$y)
ratio(pred.gbm == test$y)
ratio(pred.rf[pref.rf == pred.gbm] == test$y[pred.rf == pred.gbm])
ratio(pred.rf[pred.rf == pred.gbm] == test$y[pred.rf == pred.gbm])
q()
"abc" + 1
"abc" & 1
paste('abc', 1)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fit.rf <- train(diagnosis ~ ., data = training, method = 'rf')
fit.gbm <- train(diagnosis ~ ., data = training, method = 'gbm')
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fit.rf  <- train(diagnosis ~ ., data = training, method = 'rf')
fit.gbm <- train(diagnosis ~ ., data = training, method = 'gbm', verbose = F)
fit.lda <- train(diagnosis ~ ., data = training, method = 'lda')
trainpred.rf  <- predict(fit.rf, data = training)
trainpred.gbm <- predict(fit.gbm, data = training)
trainpred.lda <- predict(fit.lda, data = training)
trainpreds <- data.frame(diagnosis = training$diagnosis, pred.rf = trainpred.rf, pred.gbm = trainpred.gbm, pred.lda = trainpred.lda)
fit.stack <- train(diagnosis ~ ., data = trainpreds, method = 'rf')
pred.rf    <- predict(fit.rf, data = testing)
pred.gbm   <- predict(fit.gbm, data = testing)
pred.lda   <- predict(fit.lda, data = testing)
pred.stack <- predict(fit.stack, data = testing)
ratio <- function(x) {sum(x)/length(x)}
ratio.rf    <- ratio(pred.rf == testing$diagnosis)
ratio.gbm   <- ratio(pred.gbm == testing$diagnosis)
ratio.lda   <- ratio(pred.lda == testing$diagnosis)
ratio.stack <- ratio(pred.stack == testing$diagnosis)
print(paste('RF:', ratio.rf))
print(paste('GBM:', ratio.gbm))
print(paste('LDA:', ratio.lda))
print(paste('Stack:', ratio.stack))
head(testing)
head(testing[2:131])
head(testing[2:132])
head(testing[-1])
pred.rf    <- predict(fit.rf,    data = testing[-1])
pred.gbm   <- predict(fit.gbm,   data = testing[-1])
pred.lda   <- predict(fit.lda,   data = testing[-1])
pred.stack <- predict(fit.stack, data = testing[-1])
ratio <- function(x) {sum(x)/length(x)}
ratio.rf    <- ratio(pred.rf    == testing$diagnosis)
ratio.gbm   <- ratio(pred.gbm   == testing$diagnosis)
ratio.lda   <- ratio(pred.lda   == testing$diagnosis)
ratio.stack <- ratio(pred.stack == testing$diagnosis)
print(paste('RF:', ratio.rf))
print(paste('GBM:', ratio.gbm))
print(paste('LDA:', ratio.lda))
print(paste('Stack:', ratio.stack))
?predict
pred.rf    <- predict(fit.rf,    testing[-1])
pred.rf    <- predict(fit.rf,    testing)
pred.rf    <- predict(fit.rf,    testing)
pred.gbm   <- predict(fit.gbm,   testing)
pred.lda   <- predict(fit.lda,   testing)
pred.stack <- predict(fit.stack, testing)
ratio <- function(x) {sum(x)/length(x)}
ratio.rf    <- ratio(pred.rf    == testing$diagnosis)
ratio.gbm   <- ratio(pred.gbm   == testing$diagnosis)
ratio.lda   <- ratio(pred.lda   == testing$diagnosis)
ratio.stack <- ratio(pred.stack == testing$diagnosis)
print(paste('RF:', ratio.rf))
print(paste('GBM:', ratio.gbm))
print(paste('LDA:', ratio.lda))
print(paste('Stack:', ratio.stack))
fit.stack <- train(diagnosis ~ ., data = trainpreds, method = 'rf')
trainpreds <- data.frame(diagnosis = training$diagnosis, pred.rf = trainpred.rf, pred.gbm = trainpred.gbm, pred.lda = trainpred.lda)
trainpred.rf  <- predict(fit.rf,  training)
trainpred.gbm <- predict(fit.gbm, training)
trainpred.lda <- predict(fit.lda, training)
trainpreds <- data.frame(diagnosis = training$diagnosis, pred.rf = trainpred.rf, pred.gbm = trainpred.gbm, pred.lda = trainpred.lda)
fit.stack <- train(diagnosis ~ ., data = trainpreds, method = 'rf')
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fit.rf  <- train(diagnosis ~ ., data = training, method = 'rf')
fit.gbm <- train(diagnosis ~ ., data = training, method = 'gbm', verbose = F)
fit.lda <- train(diagnosis ~ ., data = training, method = 'lda')
trainpred.rf  <- predict(fit.rf,  training)
trainpred.gbm <- predict(fit.gbm, training)
trainpred.lda <- predict(fit.lda, training)
trainpreds <- data.frame(diagnosis = training$diagnosis, pred.rf = trainpred.rf, pred.gbm = trainpred.gbm, pred.lda = trainpred.lda)
fit.stack <- train(diagnosis ~ ., data = trainpreds, method = 'rf')
pred.rf    <- predict(fit.rf,    testing)
pred.gbm   <- predict(fit.gbm,   testing)
pred.lda   <- predict(fit.lda,   testing)
pred.stack <- predict(fit.stack, testing)
ratio <- function(x) {sum(x)/length(x)}
ratio.rf    <- ratio(pred.rf    == testing$diagnosis)
ratio.gbm   <- ratio(pred.gbm   == testing$diagnosis)
ratio.lda   <- ratio(pred.lda   == testing$diagnosis)
ratio.stack <- ratio(pred.stack == testing$diagnosis)
print(paste('RF:', ratio.rf))
print(paste('GBM:', ratio.gbm))
print(paste('LDA:', ratio.lda))
print(paste('Stack:', ratio.stack))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
fit.lasso <- train(CompressiveStrength ~ ., data = training, method = 'lasso')
?plot.enet
plot.enet(fit.lasso)
fit.lasso
fit.lasso$results
plot(fit.lasso)
plot(fit.lasso, xvar = 'L1norm')
fit.lasso$finalModel
fit.lasso$coefnames
fit.lasso$results
fit.lasso$finalModel
plot(fit.lasso, xvar = 'step')
typeof(fit.lasso)
fit.lasso
?enet
colnames(training)
training[-9]
enet(training[-9], training[9], lambda = 0)
enet(as.numeric(training[-9]), training[9], lambda = 0)
plot(fit.lasso)
?plot.enet
class(fit.lasso)
fit.lasso$method
fit.lasso$results
class(fit.lasso$results)
data(diabetes)
attach(diabetes)
x
object <- enet(x,y,lambda=1)
par(mfrow=c(2,2))
plot(object)
plot(object,xvar="step")
detach(diabetes)
par(mfrow=c(1,1))
plot(object, xvar='step')
install.packages("forecast")
?bats
library(forecast)
?bats
library(lubridate)
library(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit.bats <- bats(tstrain)
fc <- forecast(fit.bats)
plot(fc)
library(lubridate)
library(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit.bats <- bats(training)
fc <- forecast(fit.bats)
fit.bats <- bats(tstrain)
fit.bats <- bats(tstrain)
fc <- forecast(fit.bats)
fit.bats
testing$visitsTumblr
fc
forecast(fit.bats, h = 235, level = c(95))
fc <- forecast(fit.bats, h = 235, level = c(95))
fc$x
fc$upper
head(fc)
fc
fc$mean
fc$lower
fc$lower < testing$visitsTumblr
fc$lower < testing$visitsTumblr && fc$higher > testing$visistsTumblr
fc$higher > testing$visistsTumblr
fc$upper > testing$visitsTumblr
fc$lower < testing$visitsTumblr && fc$upper > testing$visistsTumblr
fc$lower < testing$visitsTumblr && fc$higher > testing$visistsTumblr
fc$upper > testing$visitsTumblr
up <- fc$upper > testing$visitsTumblr
low <- fc$lower < testing$visitsTumblr
low & up
both <- low & up
sum(both) / length(both)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
fit.svm <- train(CompressiveStrength ~ ., data = training, method = 'svm')
pred.svm <- predict(fit.svm, testing)
?train
getModelInfo()
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
fit.svm <- train(CompressiveStrength ~ ., data = training, method = 'lssvmLinear')
pred.svm <- predict(fit.svm, testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
head(training)
fit.svm <- train(CompressiveStrength ~ ., data = training, method = 'lssvmLinear')
fit.svm <- train(CompressiveStrength ~ ., data = training, method = "repeatedcv")
fit.svm <- train(CompressiveStrength ~ ., data = training, method = "svmLinear")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
fit.svm <- train(CompressiveStrength ~ ., data = training, method = "svmLinear")
pred.svm <- predict(fit.svm, testing)
pred.svm
?rmse
(pred.svm - testing$CompressiveStrength)^2
sqrt(sum((pred.svm - testing$CompressiveStrength)^2))
sqrt(sum((pred.svm - testing$CompressiveStrength)^2)/length(pred.svm))
sqrt(sum((pred.svm - testing$CompressiveStrength)^2))/length(pred.svm)
?e1071
install.packages("e1071")
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
svm(CompressiveStrength ~ ., data = training)
set.seed(325)
fit.svm <- svm(CompressiveStrength ~ ., data = training)
pred.svm <- predict(fit.svm, testing)
sqrt(sum((pred.svm - testing$CompressiveStrength)^2))/length(pred.svm)
sqrt(sum((pred.svm - testing$CompressiveStrength)^2)/length(pred.svm))
?enet
library(enet)
library("elasticnet", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
?enet
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
head(training[-9])
as.matrix(training[-9])
enet(as.matrix(training[-9]), training$CompressiveStrength, lambda = 0)
plot(enet(as.matrix(training[-9]), training$CompressiveStrength, lambda = 0))
?plot.enet
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
fit.lasso <- enet(as.matrix(training[-9]), training$CompressiveStrength, lambda = 0)
plot(fit.lasso, xvar = 'step')
q()
setwd("~/github/HAR-prediction/")
raw <- read.csv('pml-training.csv', header = T)
raw <- raw[colSums(is.na(raw)) == 0]
raw <- raw[-(1:5)]
raw <- raw[c(T, !sapply(raw[-c(1, 88)], is.factor), T)]
trainID  <- createDataPartition(raw$classe, p = .7, list = F)
training <- raw[trainID,]
crossval <- raw[-trainID,]
library(caret)
trainID  <- createDataPartition(raw$classe, p = .7, list = F)
training <- raw[trainID,]
crossval <- raw[-trainID,]
load('fit_rf.RData')
fit.rf$finalModel$importance
?sort
sort(fit.rf$finalModel$importance, decreasing = T)
?order
?sort
sort.int(fit.rf$finalModel$importance, decreasing = T, index.return = T)
sort.int(fit.rf$finalModel$importance, decreasing = T, index.return = T)$ix
fit.rf$finalModel$importance[sort.int(fit.rf$finalModel$importance, decreasing = T, index.return = T)$ix]
?qplot
colnames(fit.rf$finalModel$importance)
rownames(fit.rf$finalModel$importance)
rownames(fit.rf$finalModel$importance)[sort.int(fit.rf$finalModel$importance, decreasing = T, index.return = T)$ix]
rownames(fit.rf$finalModel$importance)[sort.int(fit.rf$finalModel$importance, decreasing = T, index.return = T)$ix[1:7]]
xx <- rownames(fit.rf$finalModel$importance)[sort.int(fit.rf$finalModel$importance, decreasing = T, index.return = T)$ix[1:7]]
yy <- fit.rf$finalModel$importance[sort.int(fit.rf$finalModel$importance, decreasing = T, index.return = T)$ix[1:7]]
yy
qplot(xx, yy)
qplot(xx, yy, geom = 'histogram')
qplot(xx, yy, geom = 'boxplot')
qplot(xx, yy, geom = 'histogram')
qplot(xx, yy, geom = 'histogram', stat = 'identity')
ggplot(xx, yy, geom = 'histogram', stat = 'identity')
?ggplot
ggplot(aes(xx, yy), geom = 'histogram', stat = 'identity')
qplot(xx, yy, geom = 'histogram', stat = 'identity')
qplot(xx, yy, geom = 'histogram', stat = 'identity') + opts(axis.title.x=theme_text(angle=1))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.title.x=element_text(angle=1))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.title.x=element_text(angle=45))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=45))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=10))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=20))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=40))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=35))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=45))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=30))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=25))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=15))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=15, hjust=1))
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=25, hjust=1))
varImpPlot(fit.rf$finalModel, n.var=7, main='Most important model features')
library(randomForest)
varImpPlot(fit.rf$finalModel, n.var=7, main='Most important model features')
qplot(xx, yy, geom = 'histogram', stat = 'identity') + theme(axis.text.x=element_text(angle=25, hjust=1))
qplot(xx, yy, geom = 'histogram', stat = 'identity', labs = c('a','b')) + theme(axis.text.x=element_text(angle=25, hjust=1))
qplot(xx, yy, geom = 'histogram', stat = 'identity', xlab = 'a') + theme(axis.text.x=element_text(angle=25, hjust=1))
qplot(xx, yy, geom = 'histogram', stat = 'identity', xlab = 'Feature', ylab = 'Mean Gini coefficient decrease') + theme(axis.text.x=element_text(angle=25, hjust=1))
qplot(xx, yy, geom = 'histogram', stat = 'identity', main = 'Most important model features' , xlab = 'Feature', ylab = 'Mean Gini coefficient decrease') + theme(axis.text.x=element_text(angle=25, hjust=1))
?qplot
varimp.plot$x <- xx
varimp.plot = data.frame
varimp.plot = data.frame()
varimp.plot$x <- xx
varimp.plot
?data.frame
varimp.plot <- data.frame(xx, yy)
varimp.plot
ggplot(varimp.plot, aes(x = xx, y = yy), stat = 'identity', main = 'Most important model features' , xlab = 'Feature', ylab = 'Mean Gini coefficient decrease') + theme(axis.text.x=element_text(angle=25, hjust=1))
ggplot(varimp.plot, aes(x = xx, y = yy), stat = 'identity', main = 'Most important model features' , xlab = 'Feature', ylab = 'Mean Gini coefficient decrease') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_hist()
?geom_bar
ggplot(varimp.plot, aes(x = xx, y = yy), stat = 'identity', main = 'Most important model features' , xlab = 'Feature', ylab = 'Mean Gini coefficient decrease') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar()
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features' , xlab = 'Feature', ylab = 'Mean Gini coefficient decrease') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity')
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features' , xlab = 'Feature', ylab = 'Mean Gini coefficient decrease') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', color = 'dodgerblue2')
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features' , xlab = 'Feature', ylab = 'Mean Gini coefficient decrease') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue2')
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue2') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease'))
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue2') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease')
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue2') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', main = 'a')
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue2') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease')
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue2') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease') + title('a')
ggplot(varimp.plot, aes(x = xx, y = yy), main = 'Most important model features') + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue2') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease') + title(main = 'a')
ggplot(varimp.plot, aes(x = xx, y = yy)) + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue2') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', title = 'Most important model features')
ggplot(varimp.plot, aes(x = xx, y = yy)) + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'dodgerblue') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', title = 'Most important model features')
ggplot(varimp.plot, aes(x = xx, y = yy)) + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'firered') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', title = 'Most important model features')
ggplot(varimp.plot, aes(x = xx, y = yy)) + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'orangered') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', title = 'Most important model features')
ggplot(varimp.plot, aes(x = xx, y = yy)) + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'orangered3') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', title = 'Most important model features')
fit.rf$finalModel$importance[sort.int(fit.rf$finalModel$importance, decreasing = T, index.return = T)$ix[1:7]]
varimp.plot
varimp.df <- data.frame(xx, yy)
ggplot(varimp.df, aes(x = xx, y = yy)) + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'orangered3') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', title = 'Most important model features')
ggplot(varimp.df, aes(x = xx, y = yy)) + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'orangered3', position_identity = T) + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', title = 'Most important model features')
ggplot(varimp.df, aes(x = xx, y = yy)) + theme(axis.text.x=element_text(angle=25, hjust=1)) + geom_bar(stat = 'identity', fill = 'orangered3', position = 'dodge') + labs(x = 'Feature', y = 'Mean Gini coefficient decrease', title = 'Most important model features')
q()
